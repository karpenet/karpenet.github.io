<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" >
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" />
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>KARPE/DIEM/</title>
 
    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="../style.css" media="screen" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../css/magnific-popup.css">
    

    <link href='https://fonts.googleapis.com/css?family=Righteous&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Quicksand:300,400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.1.0/github-markdown.min.css">

    <script src="../scripts/modernizr.js"></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7V2SBP59EE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7V2SBP59EE');
</script>
</head>

<body>
    <a href="#cd-nav" class="cd-nav-trigger">Menu 
        <span class="cd-nav-icon"></span>
        <svg x="0px" y="0px" width="54px" height="54px" viewBox="0 0 54 54">
            <circle fill="transparent" stroke="#90D4C5" stroke-width="2" cx="27" cy="27" r="25" stroke-dasharray="157 157" stroke-dashoffset="157"></circle>
        </svg>
    </a>
    <div id="cd-nav" class="cd-nav">
        <div class="cd-navigation-wrapper">
            <div class="cd-half-block">
                <nav>
                    <ul class="cd-primary-nav">
                        <li><a href="../index.html" class="selected">Home</a></li>
                        <li><a href="../blog.html">Blog</a></li>
                        <li><a href="../about.html">About</a></li>
                        <li><a href="../photography.html">Photography</a></li>
                        <li><a href="#">Contact</a></li>
                    </ul>
                </nav>
            </div><!-- .cd-half-block -->
        </div> <!-- .cd-navigation-wrapper -->
    </div> <!-- .cd-nav -->

    <div class="site-container">

        <header class="site-header cf">
            <div class="site-title"><a href="../index.html">KARPE/DIEM/</a></div>
            <div class="cf"></div>
        </header><!-- / .site-header -->

        <section class="site-content">
            <div class="page-desc">
                <h1>Segformer</h1>
                <article class="project markdown-body">
                    <h2 id="building-the-segformer-model-architecture">Building the SegFormer Model Architecture</h2>
<p>Instead of using a pre-built model, I decided to implement the SegFormer architecture from scratch to gain a deeper understanding of its inner workings. Here’s a brief outline of the architecture:</p>

<div style="text-align:center">
    <img src="../img/segformer/segformer-arch.png" width="75%" />
    <figcaption>Fig: Segformer Architecture</figcaption>
</div>

<h3 id="hierarchical-transformer-encoder">Hierarchical Transformer Encoder</h3>
<p>Segformer’s encoder consists of multiple transformer layers arranged in a hierarchical structure. This design allows it to capture multi-scale features from the input image, which is essential for effective segmentation.</p>

<ul>
  <li>
    <p>Stage-wise Design: The encoder is divided into several stages, where each stage processes features at different resolutions, progressively decreasing the spatial resolution and increasing the feature depth.</p>
  </li>
  <li>Patch Embedding: Similar to Vision Transformers (ViTs), the input image is split into patches, which are linearly projected into embedding vectors. However, Segformer uses overlapping patches, which help retain more spatial information compared to non-overlapping patches in standard ViTs.</li>
  <li>Multi-Head Attention with Linear Complexity: Segformer uses an efficient self-attention mechanism called Efficient Self-Attention (ESA), which reduces the quadratic complexity of vanilla self-attention to linear complexity. This allows Segformer to handle high-resolution inputs efficiently.</li>
  <li>No Positional Encoding: Unlike ViTs, which rely on positional encoding to retain spatial structure, Segformer skips positional encoding. Instead, it leverages its hierarchical architecture to capture spatial dependencies implicitly.</li>
</ul>

<h3 id="efficient-multi-head-self-attention-mhsa">Efficient Multi-Head Self-Attention (MHSA)</h3>
<p>Segformer modifies traditional MHSA to work efficiently at different resolutions. It avoids using computationally expensive self-attention layers throughout the network by introducing the following:</p>

<ul>
  <li>Depthwise Separable Convolutions: This is used to increase local inductive biases and reduce the computational cost of fully connected layers. Depthwise convolutions help capture local spatial details, compensating for the limitations of transformers in capturing fine details.</li>
  <li>Multi-Scale Feature Extraction: Each stage of the encoder extracts features at different resolutions, allowing the model to represent both local and global contextual information efficiently.</li>
</ul>

<h3 id="mlp-decoder-for-segmentation">MLP Decoder for Segmentation</h3>
<p>The decoder in Segformer is lightweight and minimalistic. Instead of using a complex decoder architecture, Segformer adopts a simple Multi-Layer Perceptron (MLP)-based decoder:</p>

<ul>
  <li>Aggregation of Multi-Scale Features: The decoder takes the output features from each stage of the encoder and aggregates them to produce the final segmentation map. The MLP layers are responsible for fusing the features across different resolutions.</li>
  <li>Per-Pixel Segmentation: After fusing the multi-scale features, the decoder predicts class scores for each pixel to generate the segmentation map.</li>
</ul>

<h3 id="design-considerations">Design Considerations</h3>
<ul>
  <li>Efficiency: Segformer is designed with efficiency in mind, utilizing lightweight components (such as linear attention and depthwise separable convolutions) to ensure fast inference, especially useful for high-resolution inputs.</li>
  <li>Flexibility: The hierarchical transformer encoder makes Segformer flexible for tasks requiring multi-scale feature extraction, which is crucial for semantic segmentation where both local and global information matter.</li>
  <li>No Positional Encodings: The absence of explicit positional encodings simplifies the model and allows it to generalize better to images with varied sizes and scales.</li>
</ul>

<h3 id="advantages">Advantages</h3>
<ul>
  <li>State-of-the-art Performance: Segformer achieves excellent performance on popular semantic segmentation benchmarks like ADE20K and Cityscapes, while being faster and more efficient than traditional convolutional neural networks (CNNs) and earlier transformer-based models like Vision Transformers (ViTs).</li>
  <li>Scalability: Due to its lightweight design and linear self-attention mechanism, Segformer scales well to larger datasets and higher-resolution images without a significant computational burden.</li>
</ul>

<iframe src="https://wandb.ai/karpenet-uofpenn/Segformer-B0/reports/Segformer-B0-Training-Run--Vmlldzo5NTU4OTIw?accessToken=70zinxzi3m6f7qyktsj9zzk6rwdqdkti4xzdfu1c8c40qdx4u3bz6loq5uqsmgl9" style="border:none;height:1024px;width:100%"></iframe>

<p><a href="https://github.com/karpenet" target="_blank" class="fa fa-github"></a></p>

<h2 id="segformer-training-pipeline">Segformer Training Pipeline</h2>

<p>These instructions can be used to train your own version of the Segformer.</p>

<h2 id="setup">Setup</h2>

<ol>
  <li>
    <p><strong>Clone the repository:</strong></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/karpenet/Segformer
<span class="nb">cd </span>Segformer
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Install the required packages:</strong></p>

    <p>Ensure you have <code class="language-plaintext highlighter-rouge">pip</code> installed, then run:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Set up Weights &amp; Biases (wandb):</strong></p>

    <ul>
      <li>Create an account on <a href="https://wandb.ai/">wandb.ai</a>.</li>
      <li>
        <p>Install the wandb CLI tool if not already installed:</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>wandb
</code></pre></div>        </div>
      </li>
      <li>
        <p>Log in to wandb using your API Key:</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wandb login
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ol>

<h2 id="training">Training</h2>

<ol>
  <li>
    <p><strong>Prepare the configuration file:</strong></p>

    <p>The training configuration is stored in <code class="language-plaintext highlighter-rouge">train_config.yaml</code>. You can modify the hyperparameters such as <code class="language-plaintext highlighter-rouge">batch_size</code>, <code class="language-plaintext highlighter-rouge">epochs</code>, <code class="language-plaintext highlighter-rouge">learning_rate</code>, and model architecture (<code class="language-plaintext highlighter-rouge">arch</code>) as needed.</p>
  </li>
  <li>
    <p><strong>Run the training script:</strong></p>

    <p>Execute the following command to start training:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python train.py
</code></pre></div>    </div>

    <p>This will initialize a wandb run, load the dataset, and start the training process. The model’s performance metrics will be logged to your wandb project.</p>
  </li>
</ol>

<h2 id="code-structure">Code Structure</h2>

<ul>
  <li><code class="language-plaintext highlighter-rouge">train.py</code>: Contains the main training loop and functions for logging metrics.</li>
  <li><code class="language-plaintext highlighter-rouge">dataset.py</code>: Handles dataset downloading, preprocessing, and loading.</li>
  <li><code class="language-plaintext highlighter-rouge">Segformer.py</code>: Defines the Segformer model architecture.</li>
  <li><code class="language-plaintext highlighter-rouge">train_config.yaml</code>: Configuration file for training hyperparameters and model architecture.</li>
</ul>

                </article>
            </div>
        <!--END .site-content-->
        </section>


 
        <nav role="navigation">
            <ul class="cd-pagination animated-buttons custom-icons">
                <li class="button"><a href="#0"><i>Prev</i></a></li>
                <li class="button-main"><a href="../index.html"><i>Portfolio</i></a></li>
                <li class="button"><a href="#0"><i>Next</i></a></li>

            </ul>
        </nav> <!-- cd-pagination-wrapper -->
 

        <footer class="site-footer cf">
            <p class="footer-text">© Copyright 2024</p>
            <nav class="social" role="navigation">
                <a href="" class="fa fa-envelope"></a>
                <a href="https://github.com/karpenet" target="_blank" class="fa fa-github"></a>
                <a href="https://in.linkedin.com/in/kedar-karpe-640b18118" target="_blank" class="fa fa-linkedin"></a>
            </nav>
        </footer>


    <!--END .site-container-->
    </div>

    <script src="../scripts/jquery-3.7.1.min.js"></script>
    <script src="../scripts/jquery.fitvids.js"></script>
    <script src="../scripts/jquery.imagesloaded.min.js"></script>
    <script src="../scripts/imgloaded.js"></script>
    <script src="../scripts/main.js"></script>  

    <script src="../scripts/modernizr.js"></script>
    <script src="../scripts/masonry.pkgd.min.js"></script>
    <script src="../scripts/jquery.magnific-popup.min.js"></script>
    <script src="../scripts/isotope.js"></script>

    <script src="../scripts/popper.js"></script>
    <script src="../scripts/bootstrap.min.js"></script>

    <script id="MathJax-script" async src= "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 

</body>
</html>